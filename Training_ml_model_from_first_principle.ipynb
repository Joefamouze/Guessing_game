{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEW4oBeN/va8zEXilqw4X0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joefamouze/Guessing_game/blob/master/Training_ml_model_from_first_principle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "FCxaWu7MXMG0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveDense:\n",
        "  def __init__(self, input_size, output_size, activation):\n",
        "    self.activation = activation\n",
        "\n",
        "    w_shape = (input_size, output_size)\n",
        "    w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "    self.W = tf.Variable(w_initial_value)\n",
        "\n",
        "    b_shape = (output_size)\n",
        "    b_initial_value = tf.zeros(b_shape)\n",
        "    self.b = tf.Variable(b_initial_value)\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "  @property\n",
        "  def weights(self):\n",
        "    return (self.W, self.b)\n"
      ],
      "metadata": {
        "id": "4wNyo5fTwsGV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveSequential:\n",
        "  def __init__(self, layers):\n",
        "    self.layers = layers\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "  @property\n",
        "  def weights(self):\n",
        "    weights = []\n",
        "    for layer in self.layers:\n",
        "      weights += layer.weights\n",
        "    return weights"
      ],
      "metadata": {
        "id": "KtdZjRho30uE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28*28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "assert len(model.weights) == 4"
      ],
      "metadata": {
        "id": "gNLzHxyG5CBh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.weights"
      ],
      "metadata": {
        "id": "fgZa6zqQ6qX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "  def __init__(self, images, labels, batch_size=128):\n",
        "    assert len(images) == len(labels)\n",
        "    self.index = 0\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "  def next(self):\n",
        "    images = self.images[self.index : self.index + self.batch_size]\n",
        "    labels = self.labels[self.index : self.index + self.batch_size]\n",
        "    self.index += self.batch_size\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "lOxaPmrv6tj5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_training_step(model, images_batch, labels_batch):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images_batch)\n",
        "    per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "    labels_batch, predictions)\n",
        "    average_loss = tf.reduce_mean(per_sample_losses)\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    update_weights(gradients, model.weights)\n",
        "  return average_loss\n",
        "\n",
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "  for g, w in zip(gradients, weights):\n",
        "    w.assign_sub(g * learning_rate)"
      ],
      "metadata": {
        "id": "i4hCnsm-8Xkw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "  for epoch_counter in range(epochs):\n",
        "    print(f\"Epoch {epoch_counter}\")\n",
        "    batch_generator = BatchGenerator(images, labels)\n",
        "    for batch_counter in range(batch_generator.num_batches):\n",
        "      images_batch, labels_batch = batch_generator.next()\n",
        "      loss = one_training_step(model, images_batch, labels_batch)\n",
        "      if batch_counter % 100 == 0:\n",
        "        print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ],
      "metadata": {
        "id": "ooF8IQ2NmP1N"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reshaping**\n",
        "\n",
        "Import Mnist datasets from tensorflow datasets. Load dataset and split them into train and test set.\n",
        "Reshaping helps you to format the data into a 2D vector for train and helps with creating consistency in the shape of the input data for **better training performance**\n",
        "\n",
        " Converting the images into a 2D array simplifies the computational process for the model. By flattening the images, the model can access and process the data more efficiently, leading to faster training and prediction times.\n",
        "\n",
        "**Normalization**\n",
        "\n",
        "Standardizing Range: Normalizing the pixel values to a range between 0 and 1 (dividing by 255 in this case) standardizes the data distribution. This standardization ensures that the model doesn't give undue weight to images with higher or lower pixel intensities\n",
        "\n",
        "Improving Gradient Descent: Normalization can improve the performance of gradient descent, the optimization algorithm commonly used in machine learning. By standardizing the data, gradient descent can take smaller and more consistent steps, leading to more stable and efficient optimization."
      ],
      "metadata": {
        "id": "41DAxqg-qgap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28*28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28*28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "sp7R1jGCobL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "predictions = model(test_images)\n",
        "# calling .numpy() on a Tensorflow tensor converts it to a Numpy tensor\n",
        "predictions = predictions.numpy()\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == test_labels\n",
        "print(f\"accuracy: {matches.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o92MbquApzmq",
        "outputId": "aa28551e-bc73-4977-d1f5-4a4f11266392"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model accuracy = 0.81 when trained with two dense layers.\n",
        "Batch_size didn't affect the accuracy"
      ],
      "metadata": {
        "id": "HpdrvktnuI6V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oAFkanufsz8U"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}